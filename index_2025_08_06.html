<html>
<head><title>Ashutosh Kumar Nirala</title>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M65TVLEF22"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-M65TVLEF22');
</script>

</head>
<body text=0038A8 bgcolor=F6F5E9>
<div style="max-width: 720px;  margin: auto;">
<i><b>Aspiration:</b> Contribution towards <a href='https://en.wikipedia.org/wiki/Artificial_general_intelligence'>AGI</a></i>.
</div> 
<hr>

<div style="max-width: 720px;  margin: auto; background-image: url(images/bkgd.png);">
<table>
<tr>

</td><td><img src='images/ProfileMe.jpg' height = 100px></td>

<td><h2>Ashutosh Kumar Nirala</h2>
<a href='old_index.html'>My previous webpage</a> (updated in 2019).<br>
email: aknirala@iastate.edu<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; akn.nirala@gmail.com<br><br>
</td><td><img src='MeSkyDiving.jpg' height = 100px></td></tr>


<tr><td colspan = 3>
Pursuing PhD (started in Fall'17) from Iowa State University, Computer Science Department. (<a href='https://docs.google.com/document/d/1n1QPyOLHj01ejyd155DdYB4JPSuJ2wMRmYUCpnsFs5k/edit'>Resume</a>)

</td>
</tr>
</table>

<hr>
<h3>PhD Stuff (at ISU): Aug 2017 - current</h3>
<ul>
<li><b>Thesis Research (under <a href='https://faculty.sites.iastate.edu/jtian/'>Prof Jin Tian</a>.)</b>: <i>Robustness and interpretability of deep learning systems:</i> I found my niche in the area of adversarial robustness and interpretability in machine learning on Spring of 2021. I learned that adversarial attacks can significantly impact any machine learning system, yet despite extensive research in this field, there is still a long way for it to be as good as biological perception. I argue that without an error correction mechanism, like what biological perception relies on, the task would remain challenging. <br><br>
Prior to this, I explored different areas such as causality, missing data, RCN, deepfakes, and GANs.</li>


<h4>Other work during PHD</h4>
<li><b>RA work: CyAds (2019-2020):</b> Under <a href='https://www.cs.iastate.edu/people/adisak-sukul'>Dr Adisak Sukul</a> (<i>NSF funded</i>). Project goal: To assess user targeting in digital politcal advertisement. Analysis indicated ad spending targeted only at state level. It has four major steps:
<ol><li>Collecting YouTube ads from different US states with different age and sex profiles. Created a chrome-extension and a Django server (to pass not a robot check).</li>
<li>Classifying the political and nonpolitical ads.</li>
<li>Applying NLP and computer vision to extract several details such as content and category (attack vs promotion vs contrast) [Ref: <a href='https://ieeexplore.ieee.org/abstract/document/7823579'>Lei Qi.</a>].</li>
<li>Analyzing the data to estimate the amount of spending, to clarify the user profiling, and so on.</li>
</ol>
</li>

<li><b>TA work: </b> I have TA-ed several courses: COMS 227: ; COMS 228; ;DS 201; COMS 311, and c and I am currently TA-ing COMS 472/572. 
<ul><li>
During this time, I also had the opportunity to deliver several lectures for the AI course, covering topics such as ML: <a href='https://iastate.webex.com/webappng/sites/iastate/recording/607f892c5187103bbf7c00505681f3e1/playback'>Intro to ML</a>, <a href='https://iastate.webex.com/webappng/sites/iastate/recording/0ef3198d531a103bb17700505681f78a/playback'>Linear Regression</a>, and <a href='https://iastate.webex.com/webappng/sites/iastate/recording/47decc8b54ac103bbfbf0050568152f3/playback'>Neural Networks</a>. Bayesian Network: <a href='https://iastate.webex.com/recordingservice/sites/iastate/recording/2da331dfc033103bbcd700505681ac1a/playback'>BN Construction</a>, <a href='https://iastate.webex.com/recordingservice/sites/iastate/recording/acf6a5e9c1c2103bbb4d00505681e27f/playback'>Inference</a>.
</li></ul>
</li>

<li>Work before finalizing my PhD topic
<ul>
<li><b>RCN</b> (last worked on JAN 2021): I came across RCN during my research into the work of Jeff Hawkins, author of "<a href='https://www.amazon.com/Intelligence-Understanding-Creation-Intelligent-Machines/dp/0805078533'>On Intelligence</a>". Initially, RCN appeared to be very promising as it achieved high robust accuracy on the MNIST dataset (<a href='https://github.com/vicariousinc/science_rcn'>as it is</a>). However, after further investigation, I came to the conclusion that neural networks are likely a generalization of RCN. This realization is documented in a <a href='https://docs.google.com/presentation/d/1YRI52-PCplAha5BO74MoIsrotV0RvQAuYTfiSUGy8Ts/edit?usp=sharing'>presentation</a> I created (Please note that the presentation reflects my preliminary research findings and is not polished or finalized as the results were inconclusive).</li>


<li><b>GAN </b> (last worked on MAY 2021): I crafted a synthetic clock dataset and trained a WGAN on it to generate synthetic clocks. During my experimentation, I attempted to change the time and style of a clock. Although I succeeded in doing so (as demonstrated <a href='images/GAN_clock.png'>here</a>, left figure shows generated clocks and in right figure I swap the time in clocks in 1st and 2nd column), I discovered that there are more advanced methods, such as Nvidia's StyleGANs, which have surpassed my work and have access to significantly more GPUs. Please find code <a href='https://github.com/aknirala/GAN/tree/master'>here</a>. A presentation covering GANs till StyleGAN is <a href='https://docs.google.com/presentation/d/15NaaU3NCRqqne21jq_sFMC7SxHamAp1cE993oeykLBM/edit?usp=sharing'>here</a>.
</li> 


<li><b>Bayesian Network</b> (last worked on JAN 2021), learning structure using partition search: <a href='https://docs.google.com/presentation/d/1wZJlrkq1Y5ILvd_icMYFIzxS9jW2Roef9HIdCkWYcgc/edit?usp=sharing'>Presentation</a> on why order search is already better.</li>

<li>Prior to this I was working on a very fascinating topic: missing data. Typically when we encouter some missing entries while training a ML model, we often discard those data-points. Sometimes we design our algorithm to work with that. However all of these makes an inherent assumption that data is missing completely at random. This is seldom the case. A better appraoch would be to reason if missingness is random or not. A good paper on this is <a href='https://proceedings.neurips.cc/paper/2013/file/0ff8033cf9437c213ee13937b1c4c455-Paper.pdf'>here</a>. (Mohan, Karthika, Judea Pearl, and Jin Tian. "Graphical models for inference with missing data." Advances in neural information processing systems 26 (2013).)</li>

</ul>
</li>


</ul>

<h3>Other Interests</h3>
<ul>

<li><b>Dream to fly</b>
<table>
<tr>
<td><a href='https://www.youtube.com/watch?v=_Qdon3JR6TE&feature=youtu.be&t=180'><img src='images\MeJumping.png' width = 100px></img></a></td>
<td>
<a href='https://www.youtube.com/watch?v=_Qdon3JR6TE&feature=youtu.be&t=180'>My first skydiving</a>. Sky Diving, is so under rated. My first skydiving adventure was an unforgettable experience. Few moments after I jumped out of the plane, it felt like I was floating on air. The peace and serenity at the top of the world was unmatched, and I couldn't help but envy the birds who can fly freely without limitations. While we have airplanes and jet engines, there's nothing quite like the feeling of soaring through the air. If only humans weren't so heavy, perhaps one day we'll have iron man suits that allow us to experience the freedom of flight just like birds.
</td></tr>
</table><br><br>
</li>

<li><b>Seeing the matrix: as it is</b>
<table>
<tr>
<td><a href='https://www.dhamma.org/en-US/index'><img src='images\vipassana.jpeg' width = 100px></img></a></td>
<td>
Search for a meaningful activity forced me to face some existential questions. In the vast expanse of the universe and eternity, nothing seemed to hold any significance. While religion attempts to address this issue, it often falls short. People are drawn to stories, tales of holy and unholy beings, Gods and Devils, and miracles. But so far, no one has been able to capture the paranormal in a scientific paper.<br><br>

Thankfully, I discovered <a href='https://www.dhamma.org/en/index'>Vipassana meditation</a>. It convinced me that the pursuit of understanding one's own mind is a far better endeavor, as the mind creates everything, including suffering. While the promise of this meditation is immense, I personally am only seeking an unwavering mind. I believe that for an unwavering mind, nothing is impossible. <br><br>

Thanks to coursera, just for curiosity, to understand more about this world, sometimes I dive into courses like <a href='Relativity/index.html'>relativity, quantum computing</a>.
</td></tr>
</table><br><br>
</li>
</ul>





<h3>Done/Maintaining</h3>

<table border = 0>
<tr><td><hr></td><td><hr></td></tr>
<tr><td>2019 08 07</td>
<td>Updated my chrome extension:
<br><a href='https://chrome.google.com/webstore/detail/annotate-web-pages/emajnoacacifjgmkkmheackniabamonm'><img src = "ExtRelated/icons/ScaledIcon.png" width = 100px/>
<br>Annotate the web/CONTEXT</a>
<ul>
<li>I have updated it few times, still have not introduced my key idea of combining tasks and notes together. </li>
<li>Before I could do that, I need to save annotation on gDrive. Someday...till then check it out and leave your feedback in the comments section.</li>
</ul>
</td></tr>

<tr><td><hr></td><td><hr></td></tr>
<tr><td>2018 12 28</td>
<td>python3TCP. A simple code to demonstrate communication over TCP in python3. Please find the writeup <a href='maintaining/python3TCP.html'>here</a>.</li>
</ul>
</td></tr>

<tr><td><hr></td><td><hr></td></tr>

<tr><td>2017 12 04</td>
<td id = "572Project"><b>Stock Market Prediction by web scraping:</b> Crawled recommendation by CNBC, and applied a simple word2Vec model with stock movement around it. Achieved an impressive 30% annual return for past couple of years.<br>
Code can't be shared cause of <i>efficient market hypothesis</i>, as I am exploiting the niche. The project was done as part of 572 course project, and has been improved a lot after that.<br>
However, publicly available data as crawled from <a href='http://www.moneycontrol.com/news/business/stocks/'>CNBC</a> (stock recommendation: 2011 - Nov 2017) and <a href='https://nseindia.com/products/content/equities/equities/eq_security.htm'>NSE</a> (stock prices: 2010 - Nov 2017) are available for download:
<ul>
<li><a href='COMS572/CNBC_StockCrawl_Jan11_Nov17.pickle.tar.gz'>CNBC Stock recommendation.</a></li>
<li><a href='COMS572/16 Company.tar.gz'>NSE Stock prices</a> (Only for 16 companies, data for all companies could be provided on request).</li>
</ul>
</td></tr>

<tr><td><hr></td><td><hr></td></tr>

<tr><td>2017 11 06</td>
<td>A quick and dirty solution to share my PC screen to my eReader. I am doing lot's of reading and it would be good if I could do it without straining my eyes. Code shared <a href='https://github.com/aknirala/SharePCScreenshot'>https://github.com/aknirala/SharePCScreenshot</a>.
</td></tr>


<tr><td><hr></td><td><hr></td></tr>

<tr><td>2017 04 29</td>
<td>(ongoing) Some math, and ML concepts:
<ul>
<li><a href='MathAndML/ShortMathsStuff.html'>Some basic math concepts</a>. More to be added in time.</li>
<li><a href='MathAndML/GaussianDistrib.html'>Gaussian distribution.</a></li>
<li><a href='MathAndML/ExponentialFamily.html'>Exponential Family distribution.</a></li>
<li><a href='MathAndML/nonParamMethods.html'>Some non-parametric methods</a></li>
</ul>
</td></tr>



<tr><td><hr></td><td><hr></td></tr>

<tr><td>2017 04 24</td>
<td>Published my first chrome extension:
<br><a href='https://chrome.google.com/webstore/detail/annotate-web-pages/emajnoacacifjgmkkmheackniabamonm'><img src = "ExtRelated/icons/Logo.png" width = 100px/>
<br>Annotate Web pages</a>
<ul>
<li>This is the first version, I would be updating it to include many more features to it.</li>
</ul>
</td></tr>

<tr><td><hr></td><td><hr></td></tr>
<tr><td>2017 03 23</td>
<td>Completed this course from Coursera:
<br><a href='https://www.coursera.org/learn/einstein-relativity/home/info'><img src='Relativity/img/Logo.jpg'/><br>
Understanding Einstein: The Special Theory of Relativity</a>
<ul><li>A write-up on this is <a href='Relativity/index.html'>here</a></li></ul>
</td></tr>

<tr><td><hr></td><td><hr></td></tr>
<tr><td>2017 03 21</td>
<td>Completed CS 224D
<br><a href=''><img src='CS224D/img/CS224D.jpg'/></a>
<br>Assignment solutions here. <a href='https://github.com/aknirala/CS224D/'>https://github.com/aknirala/CS224D/</a>
<ul>
<li>NN Forward and backward equation derivation <a href='CS224D/FowdBkws.html'>here</a>.</li>
</ul>
</td></tr>
<tr><td><hr></td><td><hr></td></tr>
</table>


<h3>Other trivia</h3>
<table border = 0>

<tr><td><hr></td><td><hr></td></tr>
<tr><td>2019 06 28</td>
<td>Why We Sleep: Unlocking the Power of Sleep and Dreams.
<br><a href='https://www.amazon.com/Why-We-Sleep-Unlocking-Dreams/dp/1501144316'><img src='https://images-na.ssl-images-amazon.com/images/I/51HL0dOfXNL._SX329_BO1,204,203,200_.jpg' width = 150px/></a>
<br>This was an amazing book. I always wondered, why rereading a paper many times in one seating didn't give me the kind of insights which I get when I read it after some time (days/weeks). As per book, during NREM sleep, day to day memories from hippocampus, are transferred to neocortex (permanent storage). This process is quite active and I believe some form of indexing ect also happens. Thus next time when we read the same thing we are making new connections which is often not possible, no matter how hard we try in the first go. Cracking this code completely would be awesome.</td></tr>

<tr><td><hr></td><td><hr></td></tr>
<tr><td>2017 04 29</td>
<td>Didn't knew that even, non-religious people are so much brain-washed.
<br><a href='https://www.youtube.com/watch?v=Ed4SeoQypy0'><img src='OtherImg/NKEscape.jpg'/>
<br>Why I escaped from my brainwashed country | Hyeonseo Lee | TEDxKyoto</a>.
<br>What is the solution? Which policy should we make? What to do?</td></tr>
<tr><td><hr></td><td><hr></td></tr>
<tr><td>2017 03 21</td>
<td>This TED talk is amazing:
<br><a href='https://www.youtube.com/watch?v=-OLFwkfPxCg'><img src='OtherImg/WaterWeired.jpg'/>
<br>The weirdness of water could be the answer | Marcia Barbosa | TEDxCER</a>
<br>Just watch it at 1.5x. The enthusiasm with which she explains things, and of course the fluency comes from absolute control/knowledge of her research, simply made my day.</td></tr>
<tr><td><hr></td><td><hr></td></tr>
</table>
</div>
</body>
</html>
